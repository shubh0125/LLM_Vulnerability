### This code block generates the result for the prompt of the "COMMIT CODE" for the parameter "CODE SIZE" and extracts 
### the numerical value and saves it in the JSON file. It uses for loop to iterate through the given number of Ids

import ollama
import re
import json
import os
import logging

class oamma:

    def test_ollama(log_file, json_file, num_of_rows, code_type, testing_parameter):

                # Check if the log file exists
        if not os.path.exists(log_file):
            # Create an empty file if it does not exist
            with open(log_file, 'w') as f:
                f.write('')
            print(f"{log_file} created.")
        else:
            print(f"{log_file} already exists.")

        # Set up logging configuration
        logging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

        # Example logging usage
        # logging.info("Logging setup complete.")

        # Load the existing JSON data from the file
        with open(f"{json_file}", "r") as file:
            data = json.load(file)

        logging.info(f"Starting to Log information about the testing Parameter {testing_parameter} for the code type {code_type}")

        for i in range(1, num_of_rows):
            code = data[f"V_{str(i).zfill(3)}"][f"{code_type}"]["Code"]
            print(f"V_{str(i).zfill(3)}")
            if(code == "" or code == "None"):
                data[f"V_{str(i).zfill(3)}"][f"{code_type}"][f"{testing_parameter}"] = "null"
                logging.info(f"Code for V_{str(i).zfill(3)} does not exist so skipping.....")
                continue
                

            var = f"""Assess the overall {testing_parameter} of the codebase for maintainability and scalability. 
            Provide your evaluation of {testing_parameter} on a scale of 1 to 5, with 1 being very vulnerable and 5 being the least vulnerable. 
            Use the format '{testing_parameter} = rating'. The code is as follows - 
                """ + " " + code

            stream = ollama.chat(
                
                model='llama3',
                messages=[{'role': 'user', 'content': var}],
                stream=True,
            )
            message_chunks = []
            rating = None
            for chunk in stream:
                # print(chunk['message']['content'], end='', flush=True)
                message_chunks.append(chunk['message']['content'])
            generated_message = ''.join(message_chunks)

            #log Generated Messages
            logging.info(f"Generated message for V_{str(i).zfill(3)}: {generated_message}")
            print("\n", generated_message) 
            print("\n******************")

            regex_pattern = f'{testing_parameter} = (\\d+)'
            match = re.search(regex_pattern, generated_message)
            if match:
                rating = int(match.group(1))
                print("\n ------ ", rating)
                logging.info(f"Extracted rating for V_{str(i).zfill(3)}: {rating}")
            else:
                logging.info(f"No Valid rating found in the generated message for V_{str(i).zfill(3)}")

            print("\n***********************************") 

            if rating is not None:
                # Update the existing 
                # JSON data with the extracted rating
                data[f"V_{str(i).zfill(3)}"][f"{code_type}"][f"{testing_parameter}"] = rating

            # Write the updated data back to the JSON file
            with open(f"{json_file}", "w") as file:
                json.dump(data, file, indent=4)

        logging.info(f"Processing information for the parameter {testing_parameter} for all the {code_type} snippets has been logged.")
        logging.info("")
        logging.info("")
