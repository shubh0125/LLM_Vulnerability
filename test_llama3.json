{
    "V_001": {
        "commit_code": {
            "Code": "static long futex_wait_restart(struct restart_block *restart)\n{\n\tu32 __user *uaddr = (u32 __user *)restart->futex.uaddr;\n\tint fshared = 0;\n\tktime_t t, *tp = NULL;\n\n\tif (restart->futex.flags & FLAGS_HAS_TIMEOUT) {\n\t\tt.tv64 = restart->futex.time;\n\t\ttp = &t;\n\t}\n\trestart->fn = do_no_restart_syscall;\n\tif (restart->futex.flags & FLAGS_SHARED)\n\t\tfshared = 1;\n\treturn (long)futex_wait(uaddr, fshared, restart->futex.val, tp,\n\t\t\t\trestart->futex.bitset,\n\t\t\t\trestart->futex.flags & FLAGS_CLOCKRT);\n}\n",
            "Size": 4,
            "Code Complexity": 3,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 3
        },
        "neutral_code": {
            "Code": "static long futex_wait_restart(struct restart_block *restart)\n{\n\tu32 __user *uaddr = (u32 __user *)restart->futex.uaddr;\n\tint fshared = 0;\n\tktime_t t, *tp = NULL;\n\n\tif (restart->futex.flags & FLAGS_HAS_TIMEOUT) {\n\t\tt.tv64 = restart->futex.time;\n\t\ttp = &t;\n\t}\n\trestart->fn = do_no_restart_syscall;\n\tif (restart->futex.flags & FLAGS_SHARED)\n\t\tfshared = 1;\n\treturn (long)futex_wait(uaddr, fshared, restart->futex.val, tp,\n\t\t\t\trestart->futex.bitset,\n\t\t\t\trestart->futex.flags & FLAGS_CLOCKRT);\n}\n",
            "Size": 4,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        }
    },
    "V_002": {
        "commit_code": {
            "Code": "static int\nlookup_pi_state(u32 uval, struct futex_hash_bucket *hb,\n\t\tunion futex_key *key, struct futex_pi_state **ps)\n{\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_q *this, *next;\n\tstruct plist_head *head;\n\tstruct task_struct *p;\n\tpid_t pid = uval & FUTEX_TID_MASK;\n\n\thead = &hb->chain;\n\n\tplist_for_each_entry_safe(this, next, head, list) {\n\t\tif (match_futex(&this->key, key)) {\n\t\t\t/*\n\t\t\t * Another waiter already exists - bump up\n\t\t\t * the refcount and return its pi_state:\n\t\t\t */\n\t\t\tpi_state = this->pi_state;\n\t\t\t/*\n\t\t\t * Userspace might have messed up non PI and PI futexes\n\t\t\t */\n\t\t\tif (unlikely(!pi_state))\n\t\t\t\treturn -EINVAL;\n\n\t\t\tWARN_ON(!atomic_read(&pi_state->refcount));\n\t\t\tWARN_ON(pid && pi_state->owner &&\n\t\t\t\tpi_state->owner->pid != pid);\n\n\t\t\tatomic_inc(&pi_state->refcount);\n\t\t\t*ps = pi_state;\n\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/*\n\t * We are the first waiter - try to look up the real owner and attach\n\t * the new pi_state to it, but bail out when TID = 0\n\t */\n\tif (!pid)\n\t\treturn -ESRCH;\n\tp = futex_find_get_task(pid);\n\tif (IS_ERR(p))\n\t\treturn PTR_ERR(p);\n\n\t/*\n\t * We need to look at the task state flags to figure out,\n\t * whether the task is exiting. To protect against the do_exit\n\t * change of the task flags, we do this protected by\n\t * p->pi_lock:\n\t */\n\traw_spin_lock_irq(&p->pi_lock);\n\tif (unlikely(p->flags & PF_EXITING)) {\n\t\t/*\n\t\t * The task is on the way out. When PF_EXITPIDONE is\n\t\t * set, we know that the task has finished the\n\t\t * cleanup:\n\t\t */\n\t\tint ret = (p->flags & PF_EXITPIDONE) ? -ESRCH : -EAGAIN;\n\n\t\traw_spin_unlock_irq(&p->pi_lock);\n\t\tput_task_struct(p);\n\t\treturn ret;\n\t}\n\n\tpi_state = alloc_pi_state();\n\n\t/*\n\t * Initialize the pi_mutex in locked state and make 'p'\n\t * the owner of it:\n\t */\n\trt_mutex_init_proxy_locked(&pi_state->pi_mutex, p);\n\n\t/* Store the key for possible exit cleanups: */\n\tpi_state->key = *key;\n\n\tWARN_ON(!list_empty(&pi_state->list));\n\tlist_add(&pi_state->list, &p->pi_state_list);\n\tpi_state->owner = p;\n\traw_spin_unlock_irq(&p->pi_lock);\n\n\tput_task_struct(p);\n\n\t*ps = pi_state;\n\n\treturn 0;\n}\n\n",
            "Size": 3,
            "Code Complexity": 4,
            "Memory Management": 3,
            "Code Clarity": 4,
            "Error Handling": 4
        },
        "neutral_code": {
            "Code": "static int\nlookup_pi_state(u32 uval, struct futex_hash_bucket *hb,\n\t\tunion futex_key *key, struct futex_pi_state **ps)\n{\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_q *this, *next;\n\tstruct plist_head *head;\n\tstruct task_struct *p;\n\tpid_t pid = uval & FUTEX_TID_MASK;\n\n\thead = &hb->chain;\n\n\tplist_for_each_entry_safe(this, next, head, list) {\n\t\tif (match_futex(&this->key, key)) {\n\t\t\t/*\n\t\t\t * Another waiter already exists - bump up\n\t\t\t * the refcount and return its pi_state:\n\t\t\t */\n\t\t\tpi_state = this->pi_state;\n\t\t\t/*\n\t\t\t * Userspace might have messed up non PI and PI futexes\n\t\t\t */\n\t\t\tif (unlikely(!pi_state))\n\t\t\t\treturn -EINVAL;\n\n\t\t\tWARN_ON(!atomic_read(&pi_state->refcount));\n\t\t\tWARN_ON(pid && pi_state->owner &&\n\t\t\t\tpi_state->owner->pid != pid);\n\n\t\t\tatomic_inc(&pi_state->refcount);\n\t\t\t*ps = pi_state;\n\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/*\n\t * We are the first waiter - try to look up the real owner and attach\n\t * the new pi_state to it, but bail out when TID = 0\n\t */\n\tif (!pid)\n\t\treturn -ESRCH;\n\tp = futex_find_get_task(pid);\n\tif (IS_ERR(p))\n\t\treturn PTR_ERR(p);\n\n\t/*\n\t * We need to look at the task state flags to figure out,\n\t * whether the task is exiting. To protect against the do_exit\n\t * change of the task flags, we do this protected by\n\t * p->pi_lock:\n\t */\n\traw_spin_lock_irq(&p->pi_lock);\n\tif (unlikely(p->flags & PF_EXITING)) {\n\t\t/*\n\t\t * The task is on the way out. When PF_EXITPIDONE is\n\t\t * set, we know that the task has finished the\n\t\t * cleanup:\n\t\t */\n\t\tint ret = (p->flags & PF_EXITPIDONE) ? -ESRCH : -EAGAIN;\n\n\t\traw_spin_unlock_irq(&p->pi_lock);\n\t\tput_task_struct(p);\n\t\treturn ret;\n\t}\n\n\tpi_state = alloc_pi_state();\n\n\t/*\n\t * Initialize the pi_mutex in locked state and make 'p'\n\t * the owner of it:\n\t */\n\trt_mutex_init_proxy_locked(&pi_state->pi_mutex, p);\n\n\t/* Store the key for possible exit cleanups: */\n\tpi_state->key = *key;\n\n\tWARN_ON(!list_empty(&pi_state->list));\n\tlist_add(&pi_state->list, &p->pi_state_list);\n\tpi_state->owner = p;\n\traw_spin_unlock_irq(&p->pi_lock);\n\n\tput_task_struct(p);\n\n\t*ps = pi_state;\n\n\treturn 0;\n}\n\n",
            "Size": 3,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        }
    },
    "V_003": {
        "commit_code": {
            "Code": "static inline int match_futex(union futex_key *key1, union futex_key *key2)\n{\n\treturn (key1 && key2\n\t\t&& key1->both.word == key2->both.word\n\t\t&& key1->both.ptr == key2->both.ptr\n\t\t&& key1->both.offset == key2->both.offset);\n}\n\n",
            "Size": 4,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        },
        "neutral_code": {
            "Code": "static inline int match_futex(union futex_key *key1, union futex_key *key2)\n{\n\treturn (key1 && key2\n\t\t&& key1->both.word == key2->both.word\n\t\t&& key1->both.ptr == key2->both.ptr\n\t\t&& key1->both.offset == key2->both.offset);\n}\n",
            "Size": 5,
            "Code Complexity": 3,
            "Memory Management": 5,
            "Code Clarity": 4,
            "Error Handling": 4
        }
    },
    "V_004": {
        "commit_code": {
            "Code": "static int refill_pi_state_cache(void)\n{\n\tstruct futex_pi_state *pi_state;\n\n\tif (likely(current->pi_state_cache))\n\t\treturn 0;\n\n\tpi_state = kzalloc(sizeof(*pi_state), GFP_KERNEL);\n\n\tif (!pi_state)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&pi_state->list);\n\t/* pi_mutex gets initialized later */\n\tpi_state->owner = NULL;\n\tatomic_set(&pi_state->refcount, 1);\n\tpi_state->key = FUTEX_KEY_INIT;\n\n\tcurrent->pi_state_cache = pi_state;\n\n\treturn 0;\n}\n\n",
            "Size": 4,
            "Code Complexity": 3,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 5
        },
        "neutral_code": {
            "Code": "static int refill_pi_state_cache(void)\n{\n\tstruct futex_pi_state *pi_state;\n\n\tif (likely(current->pi_state_cache))\n\t\treturn 0;\n\n\tpi_state = kzalloc(sizeof(*pi_state), GFP_KERNEL);\n\n\tif (!pi_state)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&pi_state->list);\n\t/* pi_mutex gets initialized later */\n\tpi_state->owner = NULL;\n\tatomic_set(&pi_state->refcount, 1);\n\tpi_state->key = FUTEX_KEY_INIT;\n\n\tcurrent->pi_state_cache = pi_state;\n\n\treturn 0;\n}\n",
            "Size": 5,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 5
        }
    },
    "V_005": {
        "commit_code": {
            "Code": "static inline int fetch_robust_entry(struct robust_list __user **entry,\n\t\t\t\t     struct robust_list __user * __user *head,\n\t\t\t\t     unsigned int *pi)\n{\n\tunsigned long uentry;\n\n\tif (get_user(uentry, (unsigned long __user *)head))\n\t\treturn -EFAULT;\n\n\t*entry = (void __user *)(uentry & ~1UL);\n\t*pi = uentry & 1;\n\n\treturn 0;\n}\n\n",
            "Size": 4,
            "Code Complexity": 3,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 3
        },
        "neutral_code": {
            "Code": "static inline int fetch_robust_entry(struct robust_list __user **entry,\n\t\t\t\t     struct robust_list __user * __user *head,\n\t\t\t\t     unsigned int *pi)\n{\n\tunsigned long uentry;\n\n\tif (get_user(uentry, (unsigned long __user *)head))\n\t\treturn -EFAULT;\n\n\t*entry = (void __user *)(uentry & ~1UL);\n\t*pi = uentry & 1;\n\n\treturn 0;\n}\n",
            "Size": 5,
            "Code Complexity": 4,
            "Memory Management": 3,
            "Code Clarity": 3,
            "Error Handling": 5
        }
    },
    "V_006": {
        "commit_code": {
            "Code": "static void free_pi_state(struct futex_pi_state *pi_state)\n{\n\tif (!atomic_dec_and_test(&pi_state->refcount))\n\t\treturn;\n\n\t/*\n\t * If pi_state->owner is NULL, the owner is most probably dying\n\t * and has cleaned up the pi_state already\n\t */\n\tif (pi_state->owner) {\n\t\traw_spin_lock_irq(&pi_state->owner->pi_lock);\n\t\tlist_del_init(&pi_state->list);\n\t\traw_spin_unlock_irq(&pi_state->owner->pi_lock);\n\n\t\trt_mutex_proxy_unlock(&pi_state->pi_mutex, pi_state->owner);\n\t}\n\n\tif (current->pi_state_cache)\n\t\tkfree(pi_state);\n\telse {\n\t\t/*\n\t\t * pi_state->list is already empty.\n\t\t * clear pi_state->owner.\n\t\t * refcount is at 0 - put it back to 1.\n\t\t */\n\t\tpi_state->owner = NULL;\n\t\tatomic_set(&pi_state->refcount, 1);\n\t\tcurrent->pi_state_cache = pi_state;\n\t}\n}\n\n\n",
            "Size": 5,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        },
        "neutral_code": {
            "Code": "static void free_pi_state(struct futex_pi_state *pi_state)\n{\n\tif (!atomic_dec_and_test(&pi_state->refcount))\n\t\treturn;\n\n\t/*\n\t * If pi_state->owner is NULL, the owner is most probably dying\n\t * and has cleaned up the pi_state already\n\t */\n\tif (pi_state->owner) {\n\t\traw_spin_lock_irq(&pi_state->owner->pi_lock);\n\t\tlist_del_init(&pi_state->list);\n\t\traw_spin_unlock_irq(&pi_state->owner->pi_lock);\n\n\t\trt_mutex_proxy_unlock(&pi_state->pi_mutex, pi_state->owner);\n\t}\n\n\tif (current->pi_state_cache)\n\t\tkfree(pi_state);\n\telse {\n\t\t/*\n\t\t * pi_state->list is already empty.\n\t\t * clear pi_state->owner.\n\t\t * refcount is at 0 - put it back to 1.\n\t\t */\n\t\tpi_state->owner = NULL;\n\t\tatomic_set(&pi_state->refcount, 1);\n\t\tcurrent->pi_state_cache = pi_state;\n\t}\n}\n",
            "Size": 4,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 5
        }
    },
    "V_007": {
        "commit_code": {
            "Code": "static inline void futex_get_mm(union futex_key *key)\n{\n\tatomic_inc(&key->private.mm->mm_count);\n\t/*\n\t * Ensure futex_get_mm() implies a full barrier such that\n\t * get_futex_key() implies a full barrier. This is relied upon\n\t * as full barrier (B), see the ordering comment above.\n\t */\n\tsmp_mb__after_atomic_inc();\n}\n\n\n",
            "Size": 4,
            "Code Complexity": 3,
            "Memory Management": 5,
            "Code Clarity": 4,
            "Error Handling": 5
        },
        "neutral_code": {
            "Code": "static inline void futex_get_mm(union futex_key *key)\n{\n\tatomic_inc(&key->private.mm->mm_count);\n\t/*\n\t * Ensure futex_get_mm() implies a full barrier such that\n\t * get_futex_key() implies a full barrier. This is relied upon\n\t * as full barrier (B), see the ordering comment above.\n\t */\n\tsmp_mb__after_atomic_inc();\n}\n",
            "Size": 5,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 5
        }
    },
    "V_008": {
        "commit_code": {
            "Code": "static int futex_wait(u32 __user *uaddr, unsigned int flags, u32 val,\n\t\t      ktime_t *abs_time, u32 bitset)\n{\n\tstruct hrtimer_sleeper timeout, *to = NULL;\n\tstruct restart_block *restart;\n\tstruct futex_hash_bucket *hb;\n\tstruct futex_q q = futex_q_init;\n\tint ret;\n\n\tif (!bitset)\n\t\treturn -EINVAL;\n\tq.bitset = bitset;\n\n\tif (abs_time) {\n\t\tto = &timeout;\n\n\t\thrtimer_init_on_stack(&to->timer, (flags & FLAGS_CLOCKRT) ?\n\t\t\t\t      CLOCK_REALTIME : CLOCK_MONOTONIC,\n\t\t\t\t      HRTIMER_MODE_ABS);\n\t\thrtimer_init_sleeper(to, current);\n\t\thrtimer_set_expires_range_ns(&to->timer, *abs_time,\n\t\t\t\t\t     current->timer_slack_ns);\n\t}\n\nretry:\n\t/*\n\t * Prepare to wait on uaddr. On success, holds hb lock and increments\n\t * q.key refs.\n\t */\n\tret = futex_wait_setup(uaddr, val, flags, &q, &hb);\n\tif (ret)\n\t\tgoto out;\n\n\t/* queue_me and wait for wakeup, timeout, or a signal. */\n\tfutex_wait_queue_me(hb, &q, to);\n\n\t/* If we were woken (and unqueued), we succeeded, whatever. */\n\tret = 0;\n\t/* unqueue_me() drops q.key ref */\n\tif (!unqueue_me(&q))\n\t\tgoto out;\n\tret = -ETIMEDOUT;\n\tif (to && !to->task)\n\t\tgoto out;\n\n\t/*\n\t * We expect signal_pending(current), but we might be the\n\t * victim of a spurious wakeup as well.\n\t */\n\tif (!signal_pending(current))\n\t\tgoto retry;\n\n\tret = -ERESTARTSYS;\n\tif (!abs_time)\n\t\tgoto out;\n\n\trestart = &current_thread_info()->restart_block;\n\trestart->fn = futex_wait_restart;\n\trestart->futex.uaddr = uaddr;\n\trestart->futex.val = val;\n\trestart->futex.time = abs_time->tv64;\n\trestart->futex.bitset = bitset;\n\trestart->futex.flags = flags | FLAGS_HAS_TIMEOUT;\n\n\tret = -ERESTART_RESTARTBLOCK;\n\nout:\n\tif (to) {\n\t\thrtimer_cancel(&to->timer);\n\t\tdestroy_hrtimer_on_stack(&to->timer);\n\t}\n\treturn ret;\n}\n\n\n",
            "Size": 3,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        },
        "neutral_code": {
            "Code": "static int futex_wait(u32 __user *uaddr, unsigned int flags, u32 val,\n\t\t      ktime_t *abs_time, u32 bitset)\n{\n\tstruct hrtimer_sleeper timeout, *to = NULL;\n\tstruct restart_block *restart;\n\tstruct futex_hash_bucket *hb;\n\tstruct futex_q q = futex_q_init;\n\tint ret;\n\n\tif (!bitset)\n\t\treturn -EINVAL;\n\tq.bitset = bitset;\n\n\tif (abs_time) {\n\t\tto = &timeout;\n\n\t\thrtimer_init_on_stack(&to->timer, (flags & FLAGS_CLOCKRT) ?\n\t\t\t\t      CLOCK_REALTIME : CLOCK_MONOTONIC,\n\t\t\t\t      HRTIMER_MODE_ABS);\n\t\thrtimer_init_sleeper(to, current);\n\t\thrtimer_set_expires_range_ns(&to->timer, *abs_time,\n\t\t\t\t\t     current->timer_slack_ns);\n\t}\n\nretry:\n\t/*\n\t * Prepare to wait on uaddr. On success, holds hb lock and increments\n\t * q.key refs.\n\t */\n\tret = futex_wait_setup(uaddr, val, flags, &q, &hb);\n\tif (ret)\n\t\tgoto out;\n\n\t/* queue_me and wait for wakeup, timeout, or a signal. */\n\tfutex_wait_queue_me(hb, &q, to);\n\n\t/* If we were woken (and unqueued), we succeeded, whatever. */\n\tret = 0;\n\t/* unqueue_me() drops q.key ref */\n\tif (!unqueue_me(&q))\n\t\tgoto out;\n\tret = -ETIMEDOUT;\n\tif (to && !to->task)\n\t\tgoto out;\n\n\t/*\n\t * We expect signal_pending(current), but we might be the\n\t * victim of a spurious wakeup as well.\n\t */\n\tif (!signal_pending(current))\n\t\tgoto retry;\n\n\tret = -ERESTARTSYS;\n\tif (!abs_time)\n\t\tgoto out;\n\n\trestart = &current_thread_info()->restart_block;\n\trestart->fn = futex_wait_restart;\n\trestart->futex.uaddr = uaddr;\n\trestart->futex.val = val;\n\trestart->futex.time = abs_time->tv64;\n\trestart->futex.bitset = bitset;\n\trestart->futex.flags = flags | FLAGS_HAS_TIMEOUT;\n\n\tret = -ERESTART_RESTARTBLOCK;\n\nout:\n\tif (to) {\n\t\thrtimer_cancel(&to->timer);\n\t\tdestroy_hrtimer_on_stack(&to->timer);\n\t}\n\treturn ret;\n}\n\n",
            "Size": 4,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        }
    },
    "V_009": {
        "commit_code": {
            "Code": "static inline void hb_waiters_dec(struct futex_hash_bucket *hb)\n{\n#ifdef CONFIG_SMP\n\tatomic_dec(&hb->waiters);\n#endif\n}\n",
            "Size": 5,
            "Code Complexity": 2,
            "Memory Management": 5,
            "Code Clarity": 5,
            "Error Handling": 5
        },
        "neutral_code": {
            "Code": "static inline void hb_waiters_dec(struct futex_hash_bucket *hb)\n{\n#ifdef CONFIG_SMP\n\tatomic_dec(&hb->waiters);\n#endif\n}\n",
            "Size": 4,
            "Code Complexity": 3,
            "Memory Management": 5,
            "Code Clarity": 5,
            "Error Handling": 5
        }
    },
    "V_0010": {
        "commit_code": {
            "Code": "static int\nlookup_pi_state(u32 uval, struct futex_hash_bucket *hb,\n\t\tunion futex_key *key, struct futex_pi_state **ps,\n\t\tstruct task_struct *task)\n{\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_q *this, *next;\n\tstruct task_struct *p;\n\tpid_t pid = uval & FUTEX_TID_MASK;\n\n\tplist_for_each_entry_safe(this, next, &hb->chain, list) {\n\t\tif (match_futex(&this->key, key)) {\n\t\t\t/*\n\t\t\t * Another waiter already exists - bump up\n\t\t\t * the refcount and return its pi_state:\n\t\t\t */\n\t\t\tpi_state = this->pi_state;\n\t\t\t/*\n\t\t\t * Userspace might have messed up non-PI and PI futexes\n\t\t\t */\n\t\t\tif (unlikely(!pi_state))\n\t\t\t\treturn -EINVAL;\n\n\t\t\tWARN_ON(!atomic_read(&pi_state->refcount));\n\n\t\t\t/*\n\t\t\t * When pi_state->owner is NULL then the owner died\n\t\t\t * and another waiter is on the fly. pi_state->owner\n\t\t\t * is fixed up by the task which acquires\n\t\t\t * pi_state->rt_mutex.\n\t\t\t *\n\t\t\t * We do not check for pid == 0 which can happen when\n\t\t\t * the owner died and robust_list_exit() cleared the\n\t\t\t * TID.\n\t\t\t */\n\t\t\tif (pid && pi_state->owner) {\n\t\t\t\t/*\n\t\t\t\t * Bail out if user space manipulated the\n\t\t\t\t * futex value.\n\t\t\t\t */\n\t\t\t\tif (pid != task_pid_vnr(pi_state->owner))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Protect against a corrupted uval. If uval\n\t\t\t * is 0x80000000 then pid is 0 and the waiter\n\t\t\t * bit is set. So the deadlock check in the\n\t\t\t * calling code has failed and we did not fall\n\t\t\t * into the check above due to !pid.\n\t\t\t */\n\t\t\tif (task && pi_state->owner == task)\n\t\t\t\treturn -EDEADLK;\n\n\t\t\tatomic_inc(&pi_state->refcount);\n\t\t\t*ps = pi_state;\n\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/*\n\t * We are the first waiter - try to look up the real owner and attach\n\t * the new pi_state to it, but bail out when TID = 0\n\t */\n\tif (!pid)\n\t\treturn -ESRCH;\n\tp = futex_find_get_task(pid);\n\tif (!p)\n\t\treturn -ESRCH;\n\n\tif (!p->mm) {\n\t\tput_task_struct(p);\n\t\treturn -EPERM;\n\t}\n\n\t/*\n\t * We need to look at the task state flags to figure out,\n\t * whether the task is exiting. To protect against the do_exit\n\t * change of the task flags, we do this protected by\n\t * p->pi_lock:\n\t */\n\traw_spin_lock_irq(&p->pi_lock);\n\tif (unlikely(p->flags & PF_EXITING)) {\n\t\t/*\n\t\t * The task is on the way out. When PF_EXITPIDONE is\n\t\t * set, we know that the task has finished the\n\t\t * cleanup:\n\t\t */\n\t\tint ret = (p->flags & PF_EXITPIDONE) ? -ESRCH : -EAGAIN;\n\n\t\traw_spin_unlock_irq(&p->pi_lock);\n\t\tput_task_struct(p);\n\t\treturn ret;\n\t}\n\n\tpi_state = alloc_pi_state();\n\n\t/*\n\t * Initialize the pi_mutex in locked state and make 'p'\n\t * the owner of it:\n\t */\n\trt_mutex_init_proxy_locked(&pi_state->pi_mutex, p);\n\n\t/* Store the key for possible exit cleanups: */\n\tpi_state->key = *key;\n\n\tWARN_ON(!list_empty(&pi_state->list));\n\tlist_add(&pi_state->list, &p->pi_state_list);\n\tpi_state->owner = p;\n\traw_spin_unlock_irq(&p->pi_lock);\n\n\tput_task_struct(p);\n\n\t*ps = pi_state;\n\n\treturn 0;\n}\n",
            "Size": 4,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        },
        "neutral_code": {
            "Code": "static int\nlookup_pi_state(u32 uval, struct futex_hash_bucket *hb,\n\t\tunion futex_key *key, struct futex_pi_state **ps,\n\t\tstruct task_struct *task)\n{\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_q *this, *next;\n\tstruct task_struct *p;\n\tpid_t pid = uval & FUTEX_TID_MASK;\n\n\tplist_for_each_entry_safe(this, next, &hb->chain, list) {\n\t\tif (match_futex(&this->key, key)) {\n\t\t\t/*\n\t\t\t * Another waiter already exists - bump up\n\t\t\t * the refcount and return its pi_state:\n\t\t\t */\n\t\t\tpi_state = this->pi_state;\n\t\t\t/*\n\t\t\t * Userspace might have messed up non-PI and PI futexes\n\t\t\t */\n\t\t\tif (unlikely(!pi_state))\n\t\t\t\treturn -EINVAL;\n\n\t\t\tWARN_ON(!atomic_read(&pi_state->refcount));\n\n\t\t\t/*\n\t\t\t * When pi_state->owner is NULL then the owner died\n\t\t\t * and another waiter is on the fly. pi_state->owner\n\t\t\t * is fixed up by the task which acquires\n\t\t\t * pi_state->rt_mutex.\n\t\t\t *\n\t\t\t * We do not check for pid == 0 which can happen when\n\t\t\t * the owner died and robust_list_exit() cleared the\n\t\t\t * TID.\n\t\t\t */\n\t\t\tif (pid && pi_state->owner) {\n\t\t\t\t/*\n\t\t\t\t * Bail out if user space manipulated the\n\t\t\t\t * futex value.\n\t\t\t\t */\n\t\t\t\tif (pid != task_pid_vnr(pi_state->owner))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Protect against a corrupted uval. If uval\n\t\t\t * is 0x80000000 then pid is 0 and the waiter\n\t\t\t * bit is set. So the deadlock check in the\n\t\t\t * calling code has failed and we did not fall\n\t\t\t * into the check above due to !pid.\n\t\t\t */\n\t\t\tif (task && pi_state->owner == task)\n\t\t\t\treturn -EDEADLK;\n\n\t\t\tatomic_inc(&pi_state->refcount);\n\t\t\t*ps = pi_state;\n\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/*\n\t * We are the first waiter - try to look up the real owner and attach\n\t * the new pi_state to it, but bail out when TID = 0\n\t */\n\tif (!pid)\n\t\treturn -ESRCH;\n\tp = futex_find_get_task(pid);\n\tif (!p)\n\t\treturn -ESRCH;\n\n\tif (!p->mm) {\n\t\tput_task_struct(p);\n\t\treturn -EPERM;\n\t}\n\n\t/*\n\t * We need to look at the task state flags to figure out,\n\t * whether the task is exiting. To protect against the do_exit\n\t * change of the task flags, we do this protected by\n\t * p->pi_lock:\n\t */\n\traw_spin_lock_irq(&p->pi_lock);\n\tif (unlikely(p->flags & PF_EXITING)) {\n\t\t/*\n\t\t * The task is on the way out. When PF_EXITPIDONE is\n\t\t * set, we know that the task has finished the\n\t\t * cleanup:\n\t\t */\n\t\tint ret = (p->flags & PF_EXITPIDONE) ? -ESRCH : -EAGAIN;\n\n\t\traw_spin_unlock_irq(&p->pi_lock);\n\t\tput_task_struct(p);\n\t\treturn ret;\n\t}\n\n\tpi_state = alloc_pi_state();\n\n\t/*\n\t * Initialize the pi_mutex in locked state and make 'p'\n\t * the owner of it:\n\t */\n\trt_mutex_init_proxy_locked(&pi_state->pi_mutex, p);\n\n\t/* Store the key for possible exit cleanups: */\n\tpi_state->key = *key;\n\n\tWARN_ON(!list_empty(&pi_state->list));\n\tlist_add(&pi_state->list, &p->pi_state_list);\n\tpi_state->owner = p;\n\traw_spin_unlock_irq(&p->pi_lock);\n\n\tput_task_struct(p);\n\n\t*ps = pi_state;\n\n\treturn 0;\n}\n\n",
            "Size": 3,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 3,
            "Error Handling": 4
        }
    },
    "V_0011": {
        "commit_code": {
            "Code": "struct dentry *__d_alloc(struct super_block *sb, const struct qstr *name)\n{\n\tstruct dentry *dentry;\n\tchar *dname;\n\n\tdentry = kmem_cache_alloc(dentry_cache, GFP_KERNEL);\n\tif (!dentry)\n\t\treturn NULL;\n\n\t/*\n\t * We guarantee that the inline name is always NUL-terminated.\n\t * This way the memcpy() done by the name switching in rename\n\t * will still always have a NUL at the end, even if we might\n\t * be overwriting an internal NUL character\n\t */\n\tdentry->d_iname[DNAME_INLINE_LEN-1] = 0;\n\tif (name->len > DNAME_INLINE_LEN-1) {\n\t\tsize_t size = offsetof(struct external_name, name[1]);\n\t\tstruct external_name *p = kmalloc(size + name->len, GFP_KERNEL);\n\t\tif (!p) {\n\t\t\tkmem_cache_free(dentry_cache, dentry); \n\t\t\treturn NULL;\n\t\t}\n\t\tatomic_set(&p->u.count, 1);\n\t\tdname = p->name;\n\t} else  {\n\t\tdname = dentry->d_iname;\n\t}\t\n\n\tdentry->d_name.len = name->len;\n\tdentry->d_name.hash = name->hash;\n\tmemcpy(dname, name->name, name->len);\n\tdname[name->len] = 0;\n\n\t/* Make sure we always see the terminating NUL character */\n\tsmp_wmb();\n\tdentry->d_name.name = dname;\n\n\tdentry->d_lockref.count = 1;\n\tdentry->d_flags = 0;\n\tspin_lock_init(&dentry->d_lock);\n\tseqcount_init(&dentry->d_seq);\n\tdentry->d_inode = NULL;\n\tdentry->d_parent = dentry;\n\tdentry->d_sb = sb;\n\tdentry->d_op = NULL;\n\tdentry->d_fsdata = NULL;\n\tINIT_HLIST_BL_NODE(&dentry->d_hash);\n\tINIT_LIST_HEAD(&dentry->d_lru);\n\tINIT_LIST_HEAD(&dentry->d_subdirs);\n\tINIT_HLIST_NODE(&dentry->d_u.d_alias);\n\tINIT_LIST_HEAD(&dentry->d_child);\n\td_set_d_op(dentry, dentry->d_sb->s_d_op);\n\n\tthis_cpu_inc(nr_dentry);\n\n\treturn dentry;\n}\n",
            "Size": 3,
            "Code Complexity": 3,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        },
        "neutral_code": {
            "Code": "struct dentry *__d_alloc(struct super_block *sb, const struct qstr *name)\n{\n\tstruct dentry *dentry;\n\tchar *dname;\n\n\tdentry = kmem_cache_alloc(dentry_cache, GFP_KERNEL);\n\tif (!dentry)\n\t\treturn NULL;\n\n\t/*\n\t * We guarantee that the inline name is always NUL-terminated.\n\t * This way the memcpy() done by the name switching in rename\n\t * will still always have a NUL at the end, even if we might\n\t * be overwriting an internal NUL character\n\t */\n\tdentry->d_iname[DNAME_INLINE_LEN-1] = 0;\n\tif (name->len > DNAME_INLINE_LEN-1) {\n\t\tsize_t size = offsetof(struct external_name, name[1]);\n\t\tstruct external_name *p = kmalloc(size + name->len, GFP_KERNEL);\n\t\tif (!p) {\n\t\t\tkmem_cache_free(dentry_cache, dentry); \n\t\t\treturn NULL;\n\t\t}\n\t\tatomic_set(&p->u.count, 1);\n\t\tdname = p->name;\n\t} else  {\n\t\tdname = dentry->d_iname;\n\t}\t\n\n\tdentry->d_name.len = name->len;\n\tdentry->d_name.hash = name->hash;\n\tmemcpy(dname, name->name, name->len);\n\tdname[name->len] = 0;\n\n\t/* Make sure we always see the terminating NUL character */\n\tsmp_wmb();\n\tdentry->d_name.name = dname;\n\n\tdentry->d_lockref.count = 1;\n\tdentry->d_flags = 0;\n\tspin_lock_init(&dentry->d_lock);\n\tseqcount_init(&dentry->d_seq);\n\tdentry->d_inode = NULL;\n\tdentry->d_parent = dentry;\n\tdentry->d_sb = sb;\n\tdentry->d_op = NULL;\n\tdentry->d_fsdata = NULL;\n\tINIT_HLIST_BL_NODE(&dentry->d_hash);\n\tINIT_LIST_HEAD(&dentry->d_lru);\n\tINIT_LIST_HEAD(&dentry->d_subdirs);\n\tINIT_HLIST_NODE(&dentry->d_u.d_alias);\n\tINIT_LIST_HEAD(&dentry->d_child);\n\td_set_d_op(dentry, dentry->d_sb->s_d_op);\n\n\tthis_cpu_inc(nr_dentry);\n\n\treturn dentry;\n}\n",
            "Size": 4,
            "Code Complexity": 3,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        }
    },
    "V_0012": {
        "commit_code": {
            "Code": "static struct dentry *__d_find_alias(struct inode *inode)\n{\n\tstruct dentry *alias, *discon_alias;\n\nagain:\n\tdiscon_alias = NULL;\n\thlist_for_each_entry(alias, &inode->i_dentry, d_u.d_alias) {\n\t\tspin_lock(&alias->d_lock);\n \t\tif (S_ISDIR(inode->i_mode) || !d_unhashed(alias)) {\n\t\t\tif (IS_ROOT(alias) &&\n\t\t\t    (alias->d_flags & DCACHE_DISCONNECTED)) {\n\t\t\t\tdiscon_alias = alias;\n\t\t\t} else {\n\t\t\t\t__dget_dlock(alias);\n\t\t\t\tspin_unlock(&alias->d_lock);\n\t\t\t\treturn alias;\n\t\t\t}\n\t\t}\n\t\tspin_unlock(&alias->d_lock);\n\t}\n\tif (discon_alias) {\n\t\talias = discon_alias;\n\t\tspin_lock(&alias->d_lock);\n\t\tif (S_ISDIR(inode->i_mode) || !d_unhashed(alias)) {\n\t\t\t__dget_dlock(alias);\n\t\t\tspin_unlock(&alias->d_lock);\n\t\t\treturn alias;\n\t\t}\n\t\tspin_unlock(&alias->d_lock);\n\t\tgoto again;\n\t}\n\treturn NULL;\n}\n",
            "Size": 4,
            "Code Complexity": 3,
            "Memory Management": 3,
            "Code Clarity": 3,
            "Error Handling": 4
        },
        "neutral_code": {
            "Code": "static struct dentry *__d_find_alias(struct inode *inode)\n{\n\tstruct dentry *alias, *discon_alias;\n\nagain:\n\tdiscon_alias = NULL;\n\thlist_for_each_entry(alias, &inode->i_dentry, d_u.d_alias) {\n\t\tspin_lock(&alias->d_lock);\n \t\tif (S_ISDIR(inode->i_mode) || !d_unhashed(alias)) {\n\t\t\tif (IS_ROOT(alias) &&\n\t\t\t    (alias->d_flags & DCACHE_DISCONNECTED)) {\n\t\t\t\tdiscon_alias = alias;\n\t\t\t} else {\n\t\t\t\t__dget_dlock(alias);\n\t\t\t\tspin_unlock(&alias->d_lock);\n\t\t\t\treturn alias;\n\t\t\t}\n\t\t}\n\t\tspin_unlock(&alias->d_lock);\n\t}\n\tif (discon_alias) {\n\t\talias = discon_alias;\n\t\tspin_lock(&alias->d_lock);\n\t\tif (S_ISDIR(inode->i_mode) || !d_unhashed(alias)) {\n\t\t\t__dget_dlock(alias);\n\t\t\tspin_unlock(&alias->d_lock);\n\t\t\treturn alias;\n\t\t}\n\t\tspin_unlock(&alias->d_lock);\n\t\tgoto again;\n\t}\n\treturn NULL;\n}\n\t\n",
            "Size": 4,
            "Code Complexity": 3,
            "Memory Management": 3,
            "Code Clarity": 3,
            "Error Handling": 4
        }
    },
    "V_0013": {
        "commit_code": {
            "Code": "static struct dentry * __d_find_any_alias(struct inode *inode)\n{\n\tstruct dentry *alias;\n\n\tif (hlist_empty(&inode->i_dentry))\n\t\treturn NULL;\n\talias = hlist_entry(inode->i_dentry.first, struct dentry, d_u.d_alias);\n\t__dget(alias);\n\treturn alias;\n}\n",
            "Size": 5,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        },
        "neutral_code": {
            "Code": "static struct dentry * __d_find_any_alias(struct inode *inode)\n{\n\tstruct dentry *alias;\n\n\tif (hlist_empty(&inode->i_dentry))\n\t\treturn NULL;\n\talias = hlist_entry(inode->i_dentry.first, struct dentry, d_u.d_alias);\n\t__dget(alias);\n\treturn alias;\n}\n\t\n",
            "Size": 5,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 5
        }
    },
    "V_0014": {
        "commit_code": {
            "Code": "static void __d_free(struct rcu_head *head)\n{\n\tstruct dentry *dentry = container_of(head, struct dentry, d_u.d_rcu);\n\n\tkmem_cache_free(dentry_cache, dentry); \n}\n",
            "Size": 5,
            "Code Complexity": 3,
            "Memory Management": 5,
            "Code Clarity": 4,
            "Error Handling": 5
        },
        "neutral_code": {
            "Code": "static void __d_free(struct rcu_head *head)\n{\n\tstruct dentry *dentry = container_of(head, struct dentry, d_u.d_rcu);\n\n\tkmem_cache_free(dentry_cache, dentry); \n}\n\t\n",
            "Size": 5,
            "Code Complexity": 3,
            "Memory Management": 5,
            "Code Clarity": 4,
            "Error Handling": 4
        }
    },
    "V_0015": {
        "commit_code": {
            "Code": "static void __d_free_external(struct rcu_head *head)\n{\n\tstruct dentry *dentry = container_of(head, struct dentry, d_u.d_rcu);\n\tkfree(external_name(dentry));\n\tkmem_cache_free(dentry_cache, dentry); \n}\n",
            "Size": 4,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 5,
            "Error Handling": 4
        },
        "neutral_code": {
            "Code": "static void __d_free_external(struct rcu_head *head)\n{\n\tstruct dentry *dentry = container_of(head, struct dentry, d_u.d_rcu);\n\tkfree(external_name(dentry));\n\tkmem_cache_free(dentry_cache, dentry); \n}\n\t\n",
            "Size": 4,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 5,
            "Error Handling": 4
        }
    },
    "V_0016": {
        "commit_code": {
            "Code": "static void __d_instantiate(struct dentry *dentry, struct inode *inode)\n{\n\tunsigned add_flags = d_flags_for_inode(inode);\n\n\tspin_lock(&dentry->d_lock);\n\t__d_set_type(dentry, add_flags);\n\tif (inode)\n\t\thlist_add_head(&dentry->d_u.d_alias, &inode->i_dentry);\n\tdentry->d_inode = inode;\n\tdentry_rcuwalk_barrier(dentry);\n\tspin_unlock(&dentry->d_lock);\n\tfsnotify_d_instantiate(dentry, inode);\n}\n",
            "Size": 4,
            "Code Complexity": 3,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 5
        },
        "neutral_code": {
            "Code": "static void __d_instantiate(struct dentry *dentry, struct inode *inode)\n{\n\tunsigned add_flags = d_flags_for_inode(inode);\n\n\tspin_lock(&dentry->d_lock);\n\t__d_set_type(dentry, add_flags);\n\tif (inode)\n\t\thlist_add_head(&dentry->d_u.d_alias, &inode->i_dentry);\n\tdentry->d_inode = inode;\n\tdentry_rcuwalk_barrier(dentry);\n\tspin_unlock(&dentry->d_lock);\n\tfsnotify_d_instantiate(dentry, inode);\n}\t\n",
            "Size": 4,
            "Code Complexity": 3,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        }
    },
    "V_0017": {
        "commit_code": {
            "Code": "static struct dentry *__d_instantiate_unique(struct dentry *entry,\n\t\t\t\t\t     struct inode *inode)\n{\n\tstruct dentry *alias;\n\tint len = entry->d_name.len;\n\tconst char *name = entry->d_name.name;\n\tunsigned int hash = entry->d_name.hash;\n\n\tif (!inode) {\n\t\t__d_instantiate(entry, NULL);\n\t\treturn NULL;\n\t}\n\n\thlist_for_each_entry(alias, &inode->i_dentry, d_u.d_alias) {\n\t\t/*\n\t\t * Don't need alias->d_lock here, because aliases with\n\t\t * d_parent == entry->d_parent are not subject to name or\n\t\t * parent changes, because the parent inode i_mutex is held.\n\t\t */\n\t\tif (alias->d_name.hash != hash)\n\t\t\tcontinue;\n\t\tif (alias->d_parent != entry->d_parent)\n\t\t\tcontinue;\n\t\tif (alias->d_name.len != len)\n\t\t\tcontinue;\n\t\tif (dentry_cmp(alias, name, len))\n\t\t\tcontinue;\n\t\t__dget(alias);\n\t\treturn alias;\n\t}\n\n\t__d_instantiate(entry, inode);\n\treturn NULL;\n}\n",
            "Size": 4,
            "Code Complexity": 4,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        },
        "neutral_code": {
            "Code": "static struct dentry *__d_instantiate_unique(struct dentry *entry,\n\t\t\t\t\t     struct inode *inode)\n{\n\tstruct dentry *alias;\n\tint len = entry->d_name.len;\n\tconst char *name = entry->d_name.name;\n\tunsigned int hash = entry->d_name.hash;\n\n\tif (!inode) {\n\t\t__d_instantiate(entry, NULL);\n\t\treturn NULL;\n\t}\n\n\thlist_for_each_entry(alias, &inode->i_dentry, d_u.d_alias) {\n\t\t/*\n\t\t * Don't need alias->d_lock here, because aliases with\n\t\t * d_parent == entry->d_parent are not subject to name or\n\t\t * parent changes, because the parent inode i_mutex is held.\n\t\t */\n\t\tif (alias->d_name.hash != hash)\n\t\t\tcontinue;\n\t\tif (alias->d_parent != entry->d_parent)\n\t\t\tcontinue;\n\t\tif (alias->d_name.len != len)\n\t\t\tcontinue;\n\t\tif (dentry_cmp(alias, name, len))\n\t\t\tcontinue;\n\t\t__dget(alias);\n\t\treturn alias;\n\t}\n\n\t__d_instantiate(entry, inode);\n\treturn NULL;\n}\t\n",
            "Size": 4,
            "Code Complexity": 4,
            "Memory Management": 5,
            "Code Clarity": 4,
            "Error Handling": 4
        }
    },
    "V_0018": {
        "commit_code": {
            "Code": "struct dentry *__d_lookup(const struct dentry *parent, const struct qstr *name)\n{\n\tunsigned int len = name->len;\n\tunsigned int hash = name->hash;\n\tconst unsigned char *str = name->name;\n\tstruct hlist_bl_head *b = d_hash(parent, hash);\n\tstruct hlist_bl_node *node;\n\tstruct dentry *found = NULL;\n\tstruct dentry *dentry;\n\n\t/*\n\t * Note: There is significant duplication with __d_lookup_rcu which is\n\t * required to prevent single threaded performance regressions\n\t * especially on architectures where smp_rmb (in seqcounts) are costly.\n\t * Keep the two functions in sync.\n\t */\n\n\t/*\n\t * The hash list is protected using RCU.\n\t *\n\t * Take d_lock when comparing a candidate dentry, to avoid races\n\t * with d_move().\n\t *\n\t * It is possible that concurrent renames can mess up our list\n\t * walk here and result in missing our dentry, resulting in the\n\t * false-negative result. d_lookup() protects against concurrent\n\t * renames using rename_lock seqlock.\n\t *\n\t * See Documentation/filesystems/path-lookup.txt for more details.\n\t */\n\trcu_read_lock();\n\t\n\thlist_bl_for_each_entry_rcu(dentry, node, b, d_hash) {\n\n\t\tif (dentry->d_name.hash != hash)\n\t\t\tcontinue;\n\n\t\tspin_lock(&dentry->d_lock);\n\t\tif (dentry->d_parent != parent)\n\t\t\tgoto next;\n\t\tif (d_unhashed(dentry))\n\t\t\tgoto next;\n\n\t\t/*\n\t\t * It is safe to compare names since d_move() cannot\n\t\t * change the qstr (protected by d_lock).\n\t\t */\n\t\tif (parent->d_flags & DCACHE_OP_COMPARE) {\n\t\t\tint tlen = dentry->d_name.len;\n\t\t\tconst char *tname = dentry->d_name.name;\n\t\t\tif (parent->d_op->d_compare(parent, dentry, tlen, tname, name))\n\t\t\t\tgoto next;\n\t\t} else {\n\t\t\tif (dentry->d_name.len != len)\n\t\t\t\tgoto next;\n\t\t\tif (dentry_cmp(dentry, str, len))\n\t\t\t\tgoto next;\n\t\t}\n\n\t\tdentry->d_lockref.count++;\n\t\tfound = dentry;\n\t\tspin_unlock(&dentry->d_lock);\n\t\tbreak;\nnext:\n\t\tspin_unlock(&dentry->d_lock);\n \t}\n \trcu_read_unlock();\n\n \treturn found;\n}\n\n",
            "Size": 4,
            "Code Complexity": 3,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        },
        "neutral_code": {
            "Code": "struct dentry *__d_lookup(const struct dentry *parent, const struct qstr *name)\n{\n\tunsigned int len = name->len;\n\tunsigned int hash = name->hash;\n\tconst unsigned char *str = name->name;\n\tstruct hlist_bl_head *b = d_hash(parent, hash);\n\tstruct hlist_bl_node *node;\n\tstruct dentry *found = NULL;\n\tstruct dentry *dentry;\n\n\t/*\n\t * Note: There is significant duplication with __d_lookup_rcu which is\n\t * required to prevent single threaded performance regressions\n\t * especially on architectures where smp_rmb (in seqcounts) are costly.\n\t * Keep the two functions in sync.\n\t */\n\n\t/*\n\t * The hash list is protected using RCU.\n\t *\n\t * Take d_lock when comparing a candidate dentry, to avoid races\n\t * with d_move().\n\t *\n\t * It is possible that concurrent renames can mess up our list\n\t * walk here and result in missing our dentry, resulting in the\n\t * false-negative result. d_lookup() protects against concurrent\n\t * renames using rename_lock seqlock.\n\t *\n\t * See Documentation/filesystems/path-lookup.txt for more details.\n\t */\n\trcu_read_lock();\n\t\n\thlist_bl_for_each_entry_rcu(dentry, node, b, d_hash) {\n\n\t\tif (dentry->d_name.hash != hash)\n\t\t\tcontinue;\n\n\t\tspin_lock(&dentry->d_lock);\n\t\tif (dentry->d_parent != parent)\n\t\t\tgoto next;\n\t\tif (d_unhashed(dentry))\n\t\t\tgoto next;\n\n\t\t/*\n\t\t * It is safe to compare names since d_move() cannot\n\t\t * change the qstr (protected by d_lock).\n\t\t */\n\t\tif (parent->d_flags & DCACHE_OP_COMPARE) {\n\t\t\tint tlen = dentry->d_name.len;\n\t\t\tconst char *tname = dentry->d_name.name;\n\t\t\tif (parent->d_op->d_compare(parent, dentry, tlen, tname, name))\n\t\t\t\tgoto next;\n\t\t} else {\n\t\t\tif (dentry->d_name.len != len)\n\t\t\t\tgoto next;\n\t\t\tif (dentry_cmp(dentry, str, len))\n\t\t\t\tgoto next;\n\t\t}\n\n\t\tdentry->d_lockref.count++;\n\t\tfound = dentry;\n\t\tspin_unlock(&dentry->d_lock);\n\t\tbreak;\nnext:\n\t\tspin_unlock(&dentry->d_lock);\n \t}\n \trcu_read_unlock();\n\n \treturn found;\n}\t\n",
            "Size": 3,
            "Code Complexity": 4,
            "Memory Management": 5,
            "Code Clarity": 4,
            "Error Handling": 4
        }
    },
    "V_0019": {
        "commit_code": {
            "Code": "static void __d_move(struct dentry *dentry, struct dentry *target,\n\t\t     bool exchange)\n{\n\tif (!dentry->d_inode)\n\t\tprintk(KERN_WARNING \"VFS: moving negative dcache entry\n\");\n\n\tBUG_ON(d_ancestor(dentry, target));\n\tBUG_ON(d_ancestor(target, dentry));\n\n\tdentry_lock_for_move(dentry, target);\n\n\twrite_seqcount_begin(&dentry->d_seq);\n\twrite_seqcount_begin_nested(&target->d_seq, DENTRY_D_LOCK_NESTED);\n\n\t/* __d_drop does write_seqcount_barrier, but they're OK to nest. */\n\n\t/*\n\t * Move the dentry to the target hash queue. Don't bother checking\n\t * for the same hash queue because of how unlikely it is.\n\t */\n\t__d_drop(dentry);\n\t__d_rehash(dentry, d_hash(target->d_parent, target->d_name.hash));\n\n\t/*\n\t * Unhash the target (d_delete() is not usable here).  If exchanging\n\t * the two dentries, then rehash onto the other's hash queue.\n\t */\n\t__d_drop(target);\n\tif (exchange) {\n\t\t__d_rehash(target,\n\t\t\t   d_hash(dentry->d_parent, dentry->d_name.hash));\n\t}\n\n\t/* Switch the names.. */\n\tif (exchange)\n\t\tswap_names(dentry, target);\n\telse\n\t\tcopy_name(dentry, target);\n\n\t/* ... and switch them in the tree */\n\tif (IS_ROOT(dentry)) {\n\t\t/* splicing a tree */\n\t\tdentry->d_parent = target->d_parent;\n\t\ttarget->d_parent = target;\n\t\tlist_del_init(&target->d_child);\n\t\tlist_move(&dentry->d_child, &dentry->d_parent->d_subdirs);\n\t} else {\n\t\t/* swapping two dentries */\n\t\tswap(dentry->d_parent, target->d_parent);\n\t\tlist_move(&target->d_child, &target->d_parent->d_subdirs);\n\t\tlist_move(&dentry->d_child, &dentry->d_parent->d_subdirs);\n\t\tif (exchange)\n\t\t\tfsnotify_d_move(target);\n\t\tfsnotify_d_move(dentry);\n\t}\n\n\twrite_seqcount_end(&target->d_seq);\n\twrite_seqcount_end(&dentry->d_seq);\n\n\tdentry_unlock_for_move(dentry, target);\n}\n",
            "Size": 3,
            "Code Complexity": 3,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        },
        "neutral_code": {
            "Code": "static void __d_move(struct dentry *dentry, struct dentry *target,\n\t\t     bool exchange)\n{\n\tif (!dentry->d_inode)\n\t\tprintk(KERN_WARNING \"VFS: moving negative dcache entry\n\");\n\n\tBUG_ON(d_ancestor(dentry, target));\n\tBUG_ON(d_ancestor(target, dentry));\n\n\tdentry_lock_for_move(dentry, target);\n\n\twrite_seqcount_begin(&dentry->d_seq);\n\twrite_seqcount_begin_nested(&target->d_seq, DENTRY_D_LOCK_NESTED);\n\n\t/* __d_drop does write_seqcount_barrier, but they're OK to nest. */\n\n\t/*\n\t * Move the dentry to the target hash queue. Don't bother checking\n\t * for the same hash queue because of how unlikely it is.\n\t */\n\t__d_drop(dentry);\n\t__d_rehash(dentry, d_hash(target->d_parent, target->d_name.hash));\n\n\t/*\n\t * Unhash the target (d_delete() is not usable here).  If exchanging\n\t * the two dentries, then rehash onto the other's hash queue.\n\t */\n\t__d_drop(target);\n\tif (exchange) {\n\t\t__d_rehash(target,\n\t\t\t   d_hash(dentry->d_parent, dentry->d_name.hash));\n\t}\n\n\t/* Switch the names.. */\n\tif (exchange)\n\t\tswap_names(dentry, target);\n\telse\n\t\tcopy_name(dentry, target);\n\n\t/* ... and switch them in the tree */\n\tif (IS_ROOT(dentry)) {\n\t\t/* splicing a tree */\n\t\tdentry->d_parent = target->d_parent;\n\t\ttarget->d_parent = target;\n\t\tlist_del_init(&target->d_child);\n\t\tlist_move(&dentry->d_child, &dentry->d_parent->d_subdirs);\n\t} else {\n\t\t/* swapping two dentries */\n\t\tswap(dentry->d_parent, target->d_parent);\n\t\tlist_move(&target->d_child, &target->d_parent->d_subdirs);\n\t\tlist_move(&dentry->d_child, &dentry->d_parent->d_subdirs);\n\t\tif (exchange)\n\t\t\tfsnotify_d_move(target);\n\t\tfsnotify_d_move(dentry);\n\t}\n\n\twrite_seqcount_end(&target->d_seq);\n\twrite_seqcount_end(&dentry->d_seq);\n\n\tdentry_unlock_for_move(dentry, target);\n}\n",
            "Size": 4,
            "Code Complexity": 3,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        }
    },
    "V_0020": {
        "commit_code": {
            "Code": "static struct dentry *__d_obtain_alias(struct inode *inode, int disconnected)\n{\n\tstatic const struct qstr anonstring = QSTR_INIT(\"/\", 1);\n\tstruct dentry *tmp;\n\tstruct dentry *res;\n\tunsigned add_flags;\n\n\tif (!inode)\n\t\treturn ERR_PTR(-ESTALE);\n\tif (IS_ERR(inode))\n\t\treturn ERR_CAST(inode);\n\n\tres = d_find_any_alias(inode);\n\tif (res)\n\t\tgoto out_iput;\n\n\ttmp = __d_alloc(inode->i_sb, &anonstring);\n\tif (!tmp) {\n\t\tres = ERR_PTR(-ENOMEM);\n\t\tgoto out_iput;\n\t}\n\n\tspin_lock(&inode->i_lock);\n\tres = __d_find_any_alias(inode);\n\tif (res) {\n\t\tspin_unlock(&inode->i_lock);\n\t\tdput(tmp);\n\t\tgoto out_iput;\n\t}\n\n\t/* attach a disconnected dentry */\n\tadd_flags = d_flags_for_inode(inode);\n\n\tif (disconnected)\n\t\tadd_flags |= DCACHE_DISCONNECTED;\n\n\tspin_lock(&tmp->d_lock);\n\ttmp->d_inode = inode;\n\ttmp->d_flags |= add_flags;\n\thlist_add_head(&tmp->d_u.d_alias, &inode->i_dentry);\n\thlist_bl_lock(&tmp->d_sb->s_anon);\n\thlist_bl_add_head(&tmp->d_hash, &tmp->d_sb->s_anon);\n\thlist_bl_unlock(&tmp->d_sb->s_anon);\n\tspin_unlock(&tmp->d_lock);\n\tspin_unlock(&inode->i_lock);\n\tsecurity_d_instantiate(tmp, inode);\n\n\treturn tmp;\n\n out_iput:\n\tif (res && !IS_ERR(res))\n\t\tsecurity_d_instantiate(res, inode);\n\tiput(inode);\n\treturn res;\n}\n",
            "Size": 3,
            "Code Complexity": 4,
            "Memory Management": 3,
            "Code Clarity": 4,
            "Error Handling": 4
        },
        "neutral_code": {
            "Code": "static struct dentry *__d_obtain_alias(struct inode *inode, int disconnected)\n{\n\tstatic const struct qstr anonstring = QSTR_INIT(\"/\", 1);\n\tstruct dentry *tmp;\n\tstruct dentry *res;\n\tunsigned add_flags;\n\n\tif (!inode)\n\t\treturn ERR_PTR(-ESTALE);\n\tif (IS_ERR(inode))\n\t\treturn ERR_CAST(inode);\n\n\tres = d_find_any_alias(inode);\n\tif (res)\n\t\tgoto out_iput;\n\n\ttmp = __d_alloc(inode->i_sb, &anonstring);\n\tif (!tmp) {\n\t\tres = ERR_PTR(-ENOMEM);\n\t\tgoto out_iput;\n\t}\n\n\tspin_lock(&inode->i_lock);\n\tres = __d_find_any_alias(inode);\n\tif (res) {\n\t\tspin_unlock(&inode->i_lock);\n\t\tdput(tmp);\n\t\tgoto out_iput;\n\t}\n\n\t/* attach a disconnected dentry */\n\tadd_flags = d_flags_for_inode(inode);\n\n\tif (disconnected)\n\t\tadd_flags |= DCACHE_DISCONNECTED;\n\n\tspin_lock(&tmp->d_lock);\n\ttmp->d_inode = inode;\n\ttmp->d_flags |= add_flags;\n\thlist_add_head(&tmp->d_u.d_alias, &inode->i_dentry);\n\thlist_bl_lock(&tmp->d_sb->s_anon);\n\thlist_bl_add_head(&tmp->d_hash, &tmp->d_sb->s_anon);\n\thlist_bl_unlock(&tmp->d_sb->s_anon);\n\tspin_unlock(&tmp->d_lock);\n\tspin_unlock(&inode->i_lock);\n\tsecurity_d_instantiate(tmp, inode);\n\n\treturn tmp;\n\n out_iput:\n\tif (res && !IS_ERR(res))\n\t\tsecurity_d_instantiate(res, inode);\n\tiput(inode);\n\treturn res;\n}\n",
            "Size": 4,
            "Code Complexity": 3,
            "Memory Management": 4,
            "Code Clarity": 4,
            "Error Handling": 4
        }
    },
    "V_0021": {
        "commit_code": {
            "Code": "",
            "Size": 0,
            "Code Complexity": 0,
            "Memory Management": 0,
            "Code Clarity": 0,
            "Error Handling": 0
        },
        "neutral_code": {
            "Code": "",
            "Size": 0,
            "Code Complexity": 0,
            "Memory Management": 0,
            "Code Clarity": 0,
            "Error Handling": 0
        }
    }
}